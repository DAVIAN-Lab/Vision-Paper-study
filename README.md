# Paper-Study

This repository provides the presentation slides of Computer Vision Study in [DAVIAN Lab](http://davian.kaist.ac.kr/) advised by professor [Jaegul Choo](https://sites.google.com/site/jaegulchoo/).


#### 발표자료 정리

|       Date       | Week | Topic | Presenters | Slides |
|:----------------:|:------:|:----------------------------------------:|:----------:|:------:|
| 2022.01.03 | Week113 | VA-RED^2 | 정채연 | [Slides](https://github.com/psh01087/Paper-Study/blob/master/Paper-PPT/Week113-VARED.pdf) |
| 2022.01.10 | Week114 | Perceiver | 이관호 | [Slides](https://github.com/psh01087/Paper-Study/blob/master/Paper-PPT/Week114-Perceiver.pdf) |
| 2022.01.17 | Week115 | PizzaGAN | 조영우 | [Slides](https://github.com/psh01087/Paper-Study/blob/master/Paper-PPT/Week115-PizzaGAN.pdf) |
| 2022.01.17 | Week115 | CLIP | 김태우 | [Slides](https://github.com/psh01087/Paper-Study/blob/master/Paper-PPT/Week115-CLIP.pdf) |
| 2022.01.24 | Week116 | Florence | 박민호| [Slides](https://github.com/psh01087/Paper-Study/blob/master/Paper-PPT/Week116-Florence.pdf) |
| 2022.01.24 | Week116 | StyleRig | 박세직 | [Slides](https://github.com/psh01087/Paper-Study/blob/master/Paper-PPT/Week116-StyleRig.pdf) |
| 2022.02.07 | Week117 | Cross-Domain Weakly Supervised Object Detection| 백서현 | [Slides](https://github.com/psh01087/Paper-Study/blob/master/Paper-PPT/Week117-Cross-Domain_Weakly_Supervised_Object_Detection.pdf) |
| 2022.02.07 | Week117 | BANMo| 김병준 | [Slides](https://github.com/psh01087/Paper-Study/blob/master/Paper-PPT/Week117-BANMo.pdf) |
| 2022.02.14 | Week118 | DyHead| 윤희원 | [Slides](https://github.com/psh01087/Paper-Study/blob/master/Paper-PPT/Week118-DyHead.pdf) |
| 2022.02.14 | Week118 | TTT++ | 곽대훈 | [Slides](https://github.com/psh01087/Paper-Study/blob/master/Paper-PPT/Week117-TTTPP.pdf) |
| 2022.02.21 | Week119 | First Order Motion Model | 김기홍 | [Slides](https://github.com/psh01087/Paper-Study/blob/master/Paper-PPT/Week119-First_Order_Motion_Model.pdf) |
| 2022.02.21 | Week119 | LIA | 이재성 | [Slides](https://github.com/psh01087/Paper-Study/blob/master/Paper-PPT/Week119-LIA.pdf) |
| 2022.03.14 | Week120 | LaMa | 윤주열 | [Slides](https://github.com/psh01087/Paper-Study/blob/master/Paper-PPT/Week120-LaMa.pdf) |
| 2022.03.14 | Week120 | CLIP-NeRF | 형준하 | [Slides](https://github.com/psh01087/Paper-Study/blob/master/Paper-PPT/Week120-CLIP-NeRF.pdf) |
| 2022.03.21 | Week121 | The Role of ImageNet Classes in Fréchet Inception Distance | 이상윤 | [Slides](https://github.com/psh01087/Paper-Study/blob/master/Paper-PPT/Week121-The_Role_of_ImageNet_Classes_in_Frechet_Inception_Distance.pdf) |
| 2022.03.21 | Week121 | Teachers Do More Than Teach | 정채연 | [Slides](https://github.com/psh01087/Paper-Study/blob/master/Paper-PPT/Week121-Teachers_Do_More_Than_Teach.pdf) |


#### 참고자료 정리
##### Week-113 (2022.01.03)
* VA-RED^2: Video Adaptive Redundancy Reduction (정채연)

  [VA-RED^2 Project Page](http://people.csail.mit.edu/bpan/va-red/)


##### Week-114 (2022.01.10)
* Perceiver: General Perception with Iterative Attention (이관호)

  [Perceiver: General Perception with Iterative Attention](https://arxiv.org/abs/2103.03206)


##### Week-115 (2022.01.17)
* How to Make a Pizza: Learning a Compositional Layer-Based GAN Model (조영우)

  [PizzaGAN](https://openaccess.thecvf.com/content_CVPR_2019/html/Papadopoulos_How_to_Make_a_Pizza_Learning_a_Compositional_Layer-Based_GAN_CVPR_2019_paper.html)

* CLIP: Connecting Text and Images (김태우)

  [CLIP: Connecting Text and Images](https://arxiv.org/abs/2103.00020)
  [CLIP OpenAI blog](https://openai.com/blog/clip/)


##### Week-116 (2022.01.24)
* Florence: A New Foundation Model for Computer Vision (박민호)

  [Florence: A New Foundation Model for Computer Vision](https://arxiv.org/abs/2111.11432)

* StyleRig: Rigging StyleGAN for 3D Control over Portrait Images (박세직)

  [StyleRig: Rigging StyleGAN for 3D Control over Portrait Images](https://openaccess.thecvf.com/content_CVPR_2020/html/Tewari_StyleRig_Rigging_StyleGAN_for_3D_Control_Over_Portrait_Images_CVPR_2020_paper.html)

##### Week-117 (2022.02.07)

* Informative and Consistent Correspondence Mining for Cross-Domain Weakly Supervised Object Detection (백서현)

  [Informative and Consistent Correspondence Mining for Cross-Domain Weakly Supervised Object Detection](https://openaccess.thecvf.com/content/CVPR2021/html/Hou_Informative_and_Consistent_Correspondence_Mining_for_Cross-Domain_Weakly_Supervised_Object_CVPR_2021_paper.html)


* BANMo: Building Animatable 3D Neural Models from Casual Videos (김병준)

  [BANMo: Building Animatable 3D Neural Models from Casual Videos](https://arxiv.org/abs/2112.12761)

##### Week-118 (2022.02.14)

* Dynamic Head: Unifying Object Detection Heads with Attentions (윤희원)

  [Dynamic Head: Unifying Object Detection Heads with Attentions](https://arxiv.org/abs/2106.08322)


* TTT++: When Does Self-Supervised Test-Time Training Fail or Thrive? (곽대훈)

  [TTT++: When Does Self-Supervised Test-Time Training Fail or Thrive?](https://proceedings.neurips.cc/paper/2021/hash/b618c3210e934362ac261db280128c22-Abstract.html)


##### Week-119 (2022.02.21)

* First Order Motion Model for Image Animation (김기홍)

  [First Order Motion Model for Image Animation](https://arxiv.org/abs/2003.00196)


* Latent Image Animator: Learning to Animate Images via Latent Space Navigation (이재성)

  [Latent Image Animator: Learning to Animate Images via Latent Space Navigation](https://openreview.net/forum?id=7r6kDq0mK_)

##### Week-120 (2022.03.14)

* LaMa: Resolution-robust Large Mask Inpainting with Fourier Convolutions (윤주열)

  [LaMa: Resolution-robust Large Mask Inpainting with Fourier Convolutions](https://arxiv.org/abs/2109.07161)


* CLIP-NeRF: Text-and-Image Driven Manipulation of Neural Radiance Fields (형준하)

  [CLIP-NeRF: Text-and-Image Driven Manipulation of Neural Radiance Fields](https://arxiv.org/pdf/2112.05139.pdf)


##### Week-121 (2022.03.21)

* The Role of ImageNet Classes in Fréchet Inception Distance (이상윤)

  [The Role of ImageNet Classes in Fréchet Inception Distance](https://arxiv.org/abs/2203.06026)


* Teachers Do More Than Teach: Compressing Image-to-Image Models (정채연)

  [Teachers Do More Than Teach: Compressing Image-to-Image Models](https://openaccess.thecvf.com/content/CVPR2021/html/Jin_Teachers_Do_More_Than_Teach_Compressing_Image-to-Image_Models_CVPR_2021_paper.html)
